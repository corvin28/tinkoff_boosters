{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_pr import * #make_counters, make_counters_test, compress_vals, replace_val, make_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/credit_train.csv', sep=';', encoding='cp1251')\n",
    "data_test = pd.read_csv('data/credit_test.csv', sep=';', encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([data, data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counters_cols = ['tariff_id', 'living_region', 'age', 'credit_count', 'overdue_credit_count',\n",
    "                 'gender', 'marital_status', 'job_position', 'credit_month', 'education']\n",
    "\n",
    "other_cols = ['credit_sum', 'score_shk', 'monthly_income', 'monthly_credit_sum',\n",
    "              'lr_median_income_dif', 'lr_median_credit_sum_dif', 'income_credit_sum_dif',\n",
    "              'income_credit_sum_frac', 'lr_median_credit_sum_frac']\n",
    "\n",
    "df.living_region.fillna('N', inplace=True)\n",
    "df.credit_count.fillna(10, inplace=True)\n",
    "df.overdue_credit_count.fillna(2, inplace=True)\n",
    "df['credit_sum'] = df.credit_sum.apply(lambda x: float(x.replace(',', '.')))\n",
    "df['score_shk'] = df.score_shk.apply(lambda x: float(x.replace(',', '.')))\n",
    "\n",
    "# нормализация имен регионов для подсчета статистик, для классификации использовались исходные\n",
    "a = ['РЕСП', 'ОБЛ', 'ОБЛАСТЬ', 'КРАЙ', 'ОБЛ.', 'РЕСП.', 'Р-Н', 'АО', 'КРАЙ.', '-', 'Г', 'Г.', 'АОБЛ', 'РЕСПУБЛИКА',\n",
    "    'ОКРУГ', 'АВТОНОМНЫЙ']\n",
    "df['living_region2'] = df.living_region.apply(lambda x: ''.join([y for y in x.upper().split() if y not in a]))\n",
    "df['living_region2'] = df.living_region2.apply(lambda x: ''.join([y for y in x.split('.') if y not in a]))\n",
    "\n",
    "df.loc[df.living_region2 == 'САХА/ЯКУТИЯ/', 'living_region2'] = 'САХА'\n",
    "df.loc[df.living_region2 == 'САХА(ЯКУТИЯ)', 'living_region2'] = 'САХА'\n",
    "df.loc[df.living_region2 == 'ХАНТЫ-МАНСИЙСКИЙЮГРА', 'living_region2'] = 'ХАНТЫ-МАНСИЙСКИЙ'\n",
    "df.loc[df.living_region2 == 'ХАНТЫ-МАНСИЙСКИЙЮ', 'living_region2'] = 'ХАНТЫ-МАНСИЙСКИЙ'\n",
    "df.loc[df.living_region2 == 'ЕВРЕЙСКАЯАВТОНОМНАЯ', 'living_region2'] = 'ЕВРЕЙСКАЯ'\n",
    "df.loc[df.living_region2 == 'ЧУВАШСКАЯЧУВАШИЯ', 'living_region2'] = 'ЧУВАШСКАЯ'\n",
    "df.loc[df.living_region2 == 'ЧУВАШИЯЧУВАШСКАЯ', 'living_region2'] = 'ЧУВАШСКАЯ'\n",
    "df.loc[df.living_region2 == 'СЕВЕРНАЯОСЕТИЯАЛАНИЯ', 'living_region2'] = 'ОСЕТИЯ'\n",
    "df.loc[df.living_region2 == 'СЕВОСЕТИЯАЛАНИЯ', 'living_region2'] = 'ОСЕТИЯ'\n",
    "df.loc[df.living_region2 == 'ГОРЬКОВСКАЯ', 'living_region2'] = 'НИЖЕГОРОДСКАЯ'\n",
    "df.loc[df.living_region2 == 'ПЕРМСКАЯ', 'living_region2'] = 'ПЕРМСКИЙ'\n",
    "df.loc[df.living_region2 == 'КАМЧАТСКАЯ', 'living_region2'] = 'КАМЧАТСКИЙ'\n",
    "df.loc[df.living_region2 == 'ЧУКОТСКИЙАO', 'living_region2'] = 'ЧУКОТСКИЙ'\n",
    "df.loc[df.living_region2 == 'АЛТАЙ', 'living_region2'] = 'АЛТАЙСКИЙ'\n",
    "\n",
    "# преобразования вещественных признаков\n",
    "f = lambda x: x.fillna(x.median(), inplace=True)\n",
    "df.groupby(df.living_region2).monthly_income.transform(f)\n",
    "\n",
    "df['monthly_credit_sum'] = df.credit_sum / df.credit_month\n",
    "\n",
    "median_income = dict(df.groupby(df.living_region2).monthly_income.median())\n",
    "df['lr_median_income_dif'] = df.monthly_income - df.living_region2.map(median_income)\n",
    "\n",
    "median_credit_sum = dict(df.groupby(df.living_region2).credit_sum.median())\n",
    "df['lr_median_credit_sum_dif'] = df.credit_sum - df.living_region2.map(median_credit_sum)\n",
    "df['lr_median_credit_sum_frac'] = df.credit_sum / df.living_region2.map(median_credit_sum)\n",
    "\n",
    "df['income_credit_sum_dif'] = df.monthly_income - df.monthly_credit_sum\n",
    "df['income_credit_sum_frac'] = df.monthly_income / df.monthly_credit_sum\n",
    "\n",
    "# Объединим редко встречающиеся значения признаков\n",
    "df.loc[df.credit_count > 10, 'credit_count'] = 10\n",
    "df.loc[df.overdue_credit_count > 2, 'overdue_credit_count'] = 2\n",
    "\n",
    "compress_vals(df, 'living_region', 5, 'N')\n",
    "compress_vals(df, 'tariff_id', 5, 2.0)\n",
    "compress_vals(df, 'job_position', 20, 'N')\n",
    "\n",
    "\n",
    "replace_val(df, 'credit_month', [30, 31, 32], 36)\n",
    "replace_val(df, 'credit_month', [21, 22, 23, 25, 26, 27, 28, 29], 24)\n",
    "replace_val(df, 'credit_month', [17], 18)\n",
    "\n",
    "for col in ['living_region', 'gender', 'marital_status', 'job_position', 'education']:\n",
    "    df[col], _ = pd.factorize(df[col])\n",
    "\n",
    "# частоты встреч\n",
    "for col in counters_cols:\n",
    "    df[col + '_count'] = df[col].map(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df.iloc[:data.shape[0], :]\n",
    "data_test = df.iloc[-data_test.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ad/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# кодирование средним таргетом\n",
    "X_train_prob = make_counters(X=data[counters_cols].values, y=data.open_account_flg.values, n_folds=10)\n",
    "X_test_prob = make_counters_test(data_test[counters_cols].values, data[counters_cols].values, \n",
    "                            data.open_account_flg.values)\n",
    "for i in range(len(counters_cols)):\n",
    "    data[counters_cols[i] + '_prob'] = X_train_prob[:, i]\n",
    "    data_test[counters_cols[i] + '_prob'] = X_test_prob[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "for name in counters_cols:\n",
    "    feature_names.append(name + '_count')\n",
    "    feature_names.append(name + '_prob')\n",
    "for name in other_cols:\n",
    "    feature_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    " learning_rate=0.01,\n",
    " n_estimators=3030,\n",
    " max_depth=5,\n",
    " min_child_weight=5,\n",
    " gamma=0.0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='binary:logistic',\n",
    " scale_pos_weight=1,\n",
    " seed=27,\n",
    " nthread=nthr)\n",
    "\n",
    "xgb.fit(data[feature_names], data.open_account_flg.values, eval_metric='auc')\n",
    "feat_imp = pd.Series(alg.booster().get_score(importance_type='gain')).sort_values(ascending=False)\n",
    "\n",
    "answer = xgb.predict_proba(data_test[feature_names])\n",
    "an = pd.DataFrame({'_ID_': _ID_, '_VAL_': answer[:, 1]})\n",
    "an.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* validation: 0.77195\n",
    "* public test: 0.7687\n",
    "* private test: 0.7713"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
